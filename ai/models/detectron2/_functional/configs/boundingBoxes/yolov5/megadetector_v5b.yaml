_BASE_: "base-yolov5.yaml"
MODEL:
  NUM_CLASSES: 3
  WEIGHTS: "https://github.com/microsoft/CameraTraps/releases/download/v5.0/md_v5b.0.0.pt"
  YOLO:
    depth_multiple: 1.33
    width_multiple: 1.25
    anchors:
      - [19, 27, 44, 40, 38, 94]
      - [96, 68, 86, 152, 180, 137]
      - [140, 301, 303, 264, 238, 542]
      - [436, 615, 739, 380, 925, 792]
    backbone:
      [[-1, 1, 'Conv', [64, 6, 2, 2]],
      [-1, 1, 'Conv', [128, 3, 2]],
      [-1, 3, 'C3', [128]],
      [-1, 1, 'Conv', [256, 3, 2]],
      [-1, 6, 'C3', [256]],
      [-1, 1, 'Conv', [512, 3, 2]],
      [-1, 9, 'C3', [512]],
      [-1, 1, 'Conv', [768, 3, 2]],
      [-1, 3, 'C3', [768]],
      [-1, 1, 'Conv', [1024, 3, 2]],
      [-1, 3, 'C3', [1024]],
      [-1, 1, 'SPPF', [1024, 5]]
      ]
    head:
      [[-1, 1, 'Conv', [768, 1, 1]],
      [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],
      [[-1, 8], 1, 'Concat', [1]],
      [-1, 3, 'C3', [768, False]],
      [-1, 1, 'Conv', [512, 1, 1]],
      [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],
      [[-1, 6], 1, 'Concat', [1]],
      [-1, 3, 'C3', [512, False]],
      [-1, 1, 'Conv', [256, 1, 1]],
      [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']],
      [[-1, 4], 1, 'Concat', [1]],
      [-1, 3, 'C3', [256, False]],
      [-1, 1, 'Conv', [256, 3, 2]],
      [[-1, 20], 1, 'Concat', [1]],
      [-1, 3, 'C3', [512, False]],
      [-1, 1, 'Conv', [512, 3, 2]],
      [[-1, 16], 1, 'Concat', [1]],
      [-1, 3, 'C3', [768, False]],
      [-1, 1, 'Conv', [768, 3, 2]],
      [[-1, 12], 1, 'Concat', [1]],
      [-1, 3, 'C3', [1024, False]],
      [[23, 26, 29, 32], 1, 'Detect', ['nc', 'anchors']]
      ]
    HYP:    # default hyperparameters; taken from https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml. Currently only contains parameters actually used in AIDE trainer; expand in future
      cls_pw: 1.0  # cls BCELoss positive_weight
      obj_pw: 1.0  # obj BCELoss positive_weight
      label_smoothing: 0.0
      fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
      box: 0.037500000000000006  # box loss gain
      obj: 3.0  # obj loss gain (scale with pixels)
      cls: 0.014062499999999999  # cls loss gain
      anchor_t: 4.0  # anchor-multiple threshold
      nms_conf_thres: 0.25
      nms_iou_thres: 0.45
      nms_single_cls: false
      nms_max_det: 300
INPUT:
  IMAGE_SIZE: 1280    # see https://github.com/microsoft/CameraTraps/blob/6b623eb4c846b00e1bc1bbd7b85e5718db753060/detection/pytorch_detector.py#L29
DATASETS:
  TRAIN: ()
  TEST: ()
LABELCLASS_NAMES:
  - "animal"
  - "person"
  - "vehicle"